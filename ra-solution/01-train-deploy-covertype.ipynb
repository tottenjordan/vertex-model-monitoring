{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62e9a10-aaed-4bec-952e-845e5da295e2",
   "metadata": {},
   "source": [
    "# Train and deploy TF model\n",
    "\n",
    "> train model with Covertype dataset\n",
    "\n",
    "**TODO:**\n",
    "* update [this example](https://github.com/GoogleCloudPlatform/mlops-on-gcp/blob/master/skew_detection/01_covertype_training_serving.ipynb) to use latest Vertex AI Model Monitoring service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f919e-44cd-418e-913e-53519c3ad9e5",
   "metadata": {},
   "source": [
    "## Load env config\n",
    "* use the prefix from 00-env-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31989817-e84d-4c08-ad71-40b85b22e7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX = ra-vmm-v1\n"
     ]
    }
   ],
   "source": [
    "# naming convention for all cloud resources\n",
    "VERSION        = \"v1\"              # TODO\n",
    "PREFIX         = f'ra-vmm-{VERSION}'   # TODO\n",
    "\n",
    "print(f\"PREFIX = {PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7b5760-001f-4a9a-bb18-d028739cffb9",
   "metadata": {},
   "source": [
    "**run the next cell to populate env vars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f32fe0-a43a-4608-863d-8f4e5e2d6689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"hybrid-vertex\"\n",
      "PROJECT_NUM              = \"934903580331\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "\n",
      "VERTEX_SA                = \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "\n",
      "PREFIX                   = \"ra-vmm-v1\"\n",
      "VERSION                  = \"v1\"\n",
      "\n",
      "BUCKET_NAME              = \"ra-vmm-v1-hybrid-vertex-bucket\"\n",
      "BUCKET_URI               = \"gs://ra-vmm-v1-hybrid-vertex-bucket\"\n",
      "DATA_GCS_PREFIX          = \"data\"\n",
      "DATA_PATH                = \"gs://ra-vmm-v1-hybrid-vertex-bucket/data\"\n",
      "\n",
      "REPOSITORY               = \"mm-ctp-ra-vmm-v1\"\n",
      "TRAIN_IMAGE_NAME         = \"train-ctp-v1\"\n",
      "REMOTE_IMAGE_NAME        = \"us-central1-docker.pkg.dev/hybrid-vertex/mm-ctp-ra-vmm-v1/train-ctp-v1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "# GCS bucket and paths\n",
    "BUCKET_NAME              = f'{PREFIX}-{PROJECT_ID}-bucket'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1e94e-edc5-4c2f-a9d4-cd4b31bf31c2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee244670-d1ac-499f-9da7-e0e19cce9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1b2a7f-508b-4bda-aa14-ccc8b3e71783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.13.0\n",
      "bigquery version: 3.11.4\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "print(\"TF version: {}\".format(tf.__version__))\n",
    "print(\"bigquery version: {}\".format(bigquery.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd6f1f-e7aa-4ff0-9866-3d4df0a98e59",
   "metadata": {},
   "source": [
    "## Define constants\n",
    "\n",
    "You can change the default values for the following constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb992cd-b8d3-4a8d-aef6-f37547a8bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_DATA_DIR = ./workspace/data\n",
      "TRAINING_DIR   = ./workspace/training\n",
      "MODEL_DIR      = ./workspace/training/exported_model\n"
     ]
    }
   ],
   "source": [
    "LOCAL_WORKSPACE = './workspace'\n",
    "LOCAL_DATA_DIR = os.path.join(LOCAL_WORKSPACE, 'data')\n",
    "\n",
    "MODEL_NAME = 'covertype_classifier'\n",
    "VERSION_NAME = VERSION \n",
    "TRAINING_DIR = os.path.join(LOCAL_WORKSPACE, 'training')\n",
    "MODEL_DIR = os.path.join(TRAINING_DIR, 'exported_model')\n",
    "\n",
    "print(f\"LOCAL_DATA_DIR = {LOCAL_DATA_DIR}\")\n",
    "print(f\"TRAINING_DIR   = {TRAINING_DIR}\")\n",
    "print(f\"MODEL_DIR      = {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586b651-db3e-4b16-b810-a5019568fde3",
   "metadata": {},
   "source": [
    "## Create a local workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6645f0e-e172-46b7-a74a-c4b1a14fd1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new workspace...\n",
      "Workspace created.\n"
     ]
    }
   ],
   "source": [
    "if tf.io.gfile.exists(LOCAL_WORKSPACE):\n",
    "    print(\"Removing previous workspace artifacts...\")\n",
    "    tf.io.gfile.rmtree(LOCAL_WORKSPACE)\n",
    "\n",
    "print(\"Creating a new workspace...\")\n",
    "tf.io.gfile.makedirs(LOCAL_WORKSPACE)\n",
    "tf.io.gfile.makedirs(LOCAL_DATA_DIR)\n",
    "\n",
    "print(\"Workspace created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01008cd-0dfd-4d2d-901f-190cc203d5c5",
   "metadata": {},
   "source": [
    "# 1. Preparing the dataset and defining the metadata\n",
    "The data in this tutorial is based on the [covertype](https://archive.ics.uci.edu/ml/datasets/covertype) dataset from UCI Machine Learning Repository. The notebook uses a version of the dataset that has been preprocessed, split, and uploaded to a public Cloud Storage bucket at the following location:\n",
    "\n",
    "`gs://workshop-datasets/covertype`\n",
    "\n",
    "For more information, see [Cover Type Dataset](https://github.com/GoogleCloudPlatform/mlops-on-gcp/tree/master/datasets/covertype)\n",
    "\n",
    "The task in this tutorial is to predict forest cover type from cartographic variables only. The aim is to build and deploy a minimal model to showcase the AI Platform Prediction request-response logging capabilities. Such logs let you perform further analysis for detecting data skews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dab41f-f4b0-4209-bcda-f9e0d2ae2d62",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6976d8e-89fa-4423-aa74-272a3accc3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_TRAIN_DATA = ./workspace/data/train.csv\n",
      "LOCAL_EVAL_DATA  = ./workspace/data/eval.csv\n"
     ]
    }
   ],
   "source": [
    "LOCAL_TRAIN_DATA = os.path.join(LOCAL_DATA_DIR, 'train.csv') \n",
    "LOCAL_EVAL_DATA = os.path.join(LOCAL_DATA_DIR, 'eval.csv')\n",
    "\n",
    "print(f\"LOCAL_TRAIN_DATA = {LOCAL_TRAIN_DATA}\")\n",
    "print(f\"LOCAL_EVAL_DATA  = {LOCAL_EVAL_DATA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7cc3a0-fb75-458a-a061-c8df4478468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AccessDeniedException: 403 934903580331-compute@developer.gserviceaccount.com does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).\n",
      "AccessDeniedException: 403 934903580331-compute@developer.gserviceaccount.com does not have storage.objects.list access to the Google Cloud Storage bucket. Permission 'storage.objects.list' denied on resource (or it may not exist).\n",
      "wc: ./workspace/data/train.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://workshop-datasets/covertype/data_validation/training/dataset.csv {LOCAL_TRAIN_DATA}\n",
    "!gsutil cp gs://workshop-datasets/covertype/data_validation/evaluation/dataset.csv {LOCAL_EVAL_DATA}\n",
    "!wc -l {LOCAL_TRAIN_DATA}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de9887-dd8d-4c91-a41b-ab883ded126c",
   "metadata": {},
   "source": [
    "View a sample of the downloaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab24547-0486-48c1-bde2-2ffd3090f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(LOCAL_TRAIN_DATA).head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a2dfa-8e8a-40df-879d-68e64a62dca9",
   "metadata": {},
   "source": [
    "## Define the metadata\n",
    "The following code shows the metadata of the dataset, which is used to create the data input function, the feature columns, and the serving function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e7f01-5c1e-4468-9f0c-d39bf9c10bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER = ['Elevation', 'Aspect', 'Slope','Horizontal_Distance_To_Hydrology',\n",
    "          'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "          'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "          'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area', 'Soil_Type',\n",
    "          'Cover_Type']\n",
    "\n",
    "TARGET_FEATURE_NAME = 'Cover_Type'\n",
    "\n",
    "TARGET_FEATURE_LABELS = ['0', '1', '2', '3', '4', '5', '6']\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = ['Aspect', 'Elevation', 'Hillshade_3pm', \n",
    "                         'Hillshade_9am', 'Hillshade_Noon', \n",
    "                         'Horizontal_Distance_To_Fire_Points',\n",
    "                         'Horizontal_Distance_To_Hydrology',\n",
    "                         'Horizontal_Distance_To_Roadways','Slope',\n",
    "                         'Vertical_Distance_To_Hydrology']\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    'Soil_Type': ['2702', '2703', '2704', '2705', '2706', '2717', '3501', '3502', \n",
    "                  '4201', '4703', '4704', '4744', '4758', '5101', '6101', '6102', \n",
    "                  '6731', '7101', '7102', '7103', '7201', '7202', '7700', '7701', \n",
    "                  '7702', '7709', '7710', '7745', '7746', '7755', '7756', '7757', \n",
    "                  '7790', '8703', '8707', '8708', '8771', '8772', '8776'], \n",
    "    'Wilderness_Area': ['Cache', 'Commanche', 'Neota', 'Rawah']\n",
    "}\n",
    "\n",
    "FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys()) + NUMERIC_FEATURE_NAMES\n",
    "\n",
    "HEADER_DEFAULTS = [[0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else ['NA'] \n",
    "                   for feature_name in HEADER]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)\n",
    "\n",
    "print(f\"FEATURE_NAMES   = {FEATURE_NAMES}\")\n",
    "print(f\"HEADER_DEFAULTS = {HEADER_DEFAULTS}\")\n",
    "print(f\"NUM_CLASSES     = {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263fac1-f0e6-4bd9-adfc-c43e5d77d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = f'''\n",
    "USER_AGE_LOOKUP       = {USER_AGE_LOOKUP}\n",
    "USER_AGE_DIM          = {USER_AGE_DIM}\n",
    "\n",
    "USER_OCC_LOOKUP       = {USER_OCC_LOOKUP}\n",
    "USER_OCC_DIM          = {USER_OCC_DIM}\n",
    "\n",
    "MOVIE_GEN_LOOKUP      = {MOVIE_GEN_LOOKUP}\n",
    "MOVIE_GEN_DIM         = {MOVIE_GEN_DIM}\n",
    "\n",
    "MOVIELENS_NUM_MOVIES  = {MOVIELENS_NUM_MOVIES}\n",
    "MOVIELENS_NUM_USERS   = {MOVIELENS_NUM_USERS}\n",
    "'''\n",
    "# TODO - cleanup\n",
    "with open(f'{REPO_DOCKER_PATH_PREFIX}/{RL_SUB_DIR}/data_config.py', 'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92813e6-07f8-42db-8a67-3bab62a1cf7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e84449-3127-4f1f-8874-6cd7d9fe7cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d371b65-b614-4860-af06-5c1335b5e1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
